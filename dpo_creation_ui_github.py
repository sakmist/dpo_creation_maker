import gradio as gr
import json
import os
import logging
from openai import OpenAI
import time

# --- åŸºç¡€é…ç½® ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger()

# --- åº”ç”¨é…ç½® ---

client_instance = OpenAI(api_key="not-needed", base_url="http://192.168.1.22:1234/v1")
MODEL_NAME = 'gemma-3-27b-comment-0804'
OUTPUT_FILE = "dpo_dataset_batch_v7.jsonl"
SESSION_FILE = "annotation_session.json"
MAX_RESPONSES = 20  # UIèƒ½å¤„ç†çš„æœ€å¤§å›å¤æ•°

# é»˜è®¤çš„ç”¨æˆ·æç¤º
INITIAL_USER_PROMPT = '''ä½ æ˜¯ç”·å¨˜å—ï¼Ÿå¾ˆå¯çˆ±çœ‹çœ‹å¥³è£…'''


# --- æ ¸å¿ƒé€»è¾‘ ---

def get_system_prompts():
    """ä½ è‡ªå·±åŠ è½½systemçš„ä»£ç """

   #TODO:éœ€è¦åŠ å…¥è‡ªå·±çš„ä»£ç 

    system_list = ['ä½ ä¸ªç”·å¨˜ ï¼Œå›ç­”å·²å–µç»“å°¾']
    logger.info(f"åŠ è½½äº† {len(system_list)} ä¸ªç‹¬ç«‹çš„ç³»ç»Ÿæç¤ºã€‚")
    return list(system_list)


def _generate_n_responses(system_prompt, user_prompt, n):
    messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}]
    responses = []
    for i in range(n):
        try:
            completion = client_instance.chat.completions.create(model=MODEL_NAME, messages=messages, temperature=0.95,
                                                                 top_p=0.95)
            responses.append(completion.choices[0].message.content)
            time.sleep(0.1)
        except Exception as e:
            error_msg = f"API åœ¨ç”Ÿæˆç¬¬ #{i + 1} ä¸ªå›å¤æ—¶å‡ºé”™: {e}"
            logger.error(error_msg)
            responses.append(error_msg)
    return responses


# --- ä¼šè¯ä¸æ–‡ä»¶ç®¡ç† ---

def save_session(queue, index, dpo_data):
    session_data = {"annotation_queue": queue, "current_index": index, "dpo_data": dpo_data}
    try:
        with open(SESSION_FILE, 'w', encoding='utf-8') as f:
            json.dump(session_data, f, ensure_ascii=False, indent=4)
        logger.info(f"ä¼šè¯å·²ä¿å­˜åˆ° {SESSION_FILE}")
    except Exception as e:
        logger.error(f"ä¿å­˜ä¼šè¯å¤±è´¥: {e}")


def load_session():
    if not os.path.exists(SESSION_FILE): return None
    try:
        with open(SESSION_FILE, 'r', encoding='utf-8') as f:
            session_data = json.load(f)
        logger.info(f"æˆåŠŸä» {SESSION_FILE} åŠ è½½ä¼šè¯ã€‚")
        return session_data
    except Exception as e:
        logger.error(f"åŠ è½½ä¼šè¯å¤±è´¥: {e}")
        return None


def clear_session():
    if os.path.exists(SESSION_FILE):
        os.remove(SESSION_FILE)
        logger.info(f"æ—§çš„ä¼šè¯æ–‡ä»¶ {SESSION_FILE} å·²è¢«åˆ é™¤ã€‚")


def append_to_dataset_file(new_entries):
    if not new_entries: return
    try:
        with open(OUTPUT_FILE, 'a', encoding='utf-8') as f:
            for entry in new_entries:
                f.write(json.dumps(entry, ensure_ascii=False) + '\n')
        feedback = f"ğŸ’¾ å·²è‡ªåŠ¨ä¿å­˜ {len(new_entries)} æ¡æ–°è®°å½•ã€‚"
        gr.Info(feedback)
        logger.info(feedback)
    except Exception as e:
        logger.error(f"æ–‡ä»¶è¿½åŠ é”™è¯¯: {e}")
        gr.Error(f"æ–‡ä»¶è¿½åŠ é”™è¯¯: {e}")


# --- Gradio UI å‡½æ•° ---

def display_annotation_item(annotation_queue, current_index, dpo_data):
    """æ ¸å¿ƒUIæ›´æ–°å‡½æ•°ã€‚åªè¿”å›ä¸»å†…å®¹æ›´æ–°ï¼Œä¸åŒ…å«checkboxã€‚"""
    total_items = len(annotation_queue)

    if current_index >= total_items:
        return [
            annotation_queue, current_index, dpo_data,
            gr.update(visible=False), gr.update(visible=False), gr.update(visible=True),
            None, None, "### ğŸ‰ å…¨éƒ¨å®¡æ ¸å®Œæˆï¼", dpo_data
        ] + [gr.update(value="", visible=False)] * MAX_RESPONSES + [gr.update(visible=False)] * MAX_RESPONSES

    item = annotation_queue[current_index]
    num_responses = len(item['responses'])
    progress_text = f"### æ­£åœ¨å®¡æ ¸ç¬¬ {current_index + 1} / {total_items} ç»„"

    row_updates = [gr.update(visible=False)] * MAX_RESPONSES
    text_updates = [gr.update(value="", visible=False)] * MAX_RESPONSES

    for i in range(num_responses):
        row_updates[i] = gr.update(visible=True)
        text_updates[i] = gr.update(value=item['responses'][i], visible=True)

    return [
        annotation_queue, current_index, dpo_data,
        gr.update(visible=False), gr.update(visible=True), gr.update(visible=False),
        item['system'], item['user'], progress_text, dpo_data
    ] + text_updates + row_updates


def reset_checkboxes_only(*args):
    """ä¸€ä¸ªä¸“é—¨ç”¨äºé‡ç½®å¤é€‰æ¡†çš„å‡½æ•°ï¼Œä»¥ç¡®ä¿å¯é æ€§ã€‚"""
    return [False for i in args]


def start_batch_generation(user_prompt, num_responses, progress=gr.Progress(track_tqdm=True)):
    if not user_prompt: raise gr.Error("ç”¨æˆ·æç¤ºä¸èƒ½ä¸ºç©ºã€‚")
    clear_session()
    system_prompts = get_system_prompts()
    if not system_prompts or "é”™è¯¯" in system_prompts[0]: raise gr.Error("æ— æ³•åŠ è½½æœ‰æ•ˆçš„ç³»ç»Ÿæç¤ºã€‚")
    annotation_queue = []
    for sp in progress.tqdm(system_prompts, desc="æ­£åœ¨ç”Ÿæˆæ‰€æœ‰å›å¤ç»„..."):
        responses = _generate_n_responses(sp, user_prompt, num_responses)
        annotation_queue.append({"system": sp, "user": user_prompt, "responses": responses})
    if not annotation_queue: raise gr.Error("ç”Ÿæˆä»»ä½•å›å¤å¤±è´¥ã€‚")
    save_session(annotation_queue, 0, [])
    return display_annotation_item(annotation_queue, 0, [])


def resume_flow():
    session_data = load_session()
    if session_data is None:
        gr.Warning("æœªæ‰¾åˆ°å¯æ¢å¤çš„ä¼šè¯æ–‡ä»¶ã€‚")
        return [gr.update()] * (10 + MAX_RESPONSES * 2)
    gr.Info("å·²æˆåŠŸåŠ è½½å¹¶æ¢å¤ä¸Šæ¬¡çš„ä¼šè¯ï¼")
    return display_annotation_item(
        session_data["annotation_queue"], session_data["current_index"], session_data["dpo_data"]
    )


def regenerate_current_set(annotation_queue, current_index, dpo_data):
    gr.Info("ğŸ”„ æ­£åœ¨é‡æ–°ç”Ÿæˆå›å¤ç»„...")
    current_item = annotation_queue[current_index]
    num_responses = len(current_item['responses'])
    new_responses = _generate_n_responses(current_item['system'], current_item['user'], num_responses)
    annotation_queue[current_index]['responses'] = new_responses
    save_session(annotation_queue, current_index, dpo_data)
    logger.info(f"å·²ä¸ºç´¢å¼• {current_index} é‡æ–°ç”Ÿæˆã€‚")
    text_updates = [gr.update(value=new_responses[i]) for i in range(num_responses)]
    text_updates.extend([gr.update(value="")] * (MAX_RESPONSES - num_responses))
    return [annotation_queue] + text_updates


def process_and_advance(dpo_data, annotation_queue, current_index, *all_inputs):
    edited_responses = all_inputs[:MAX_RESPONSES]
    checkbox_values = all_inputs[MAX_RESPONSES:]
    current_item = annotation_queue[current_index]
    num_active_responses = len(current_item['responses'])
    chosen_indices = [i for i, val in enumerate(checkbox_values) if val and i < num_active_responses]
    rejected_indices = [i for i, val in enumerate(checkbox_values) if not val and i < num_active_responses]

    newly_created_pairs = []
    if not chosen_indices or not rejected_indices:
        logger.info(f"ç¬¬ #{current_index + 1} ç»„å·²è·³è¿‡ã€‚")
    else:
        for chosen_idx in chosen_indices:
            for rejected_idx in rejected_indices:
                new_entry = {"messages": [{"role": "system", "content": current_item['system']},
                                          {"role": "user", "content": current_item['user']},
                                          {"role": "assistant", "content": edited_responses[chosen_idx]}],
                             "rejected_response": edited_responses[rejected_idx]}
                newly_created_pairs.append(new_entry)
        append_to_dataset_file(newly_created_pairs)
        dpo_data.extend(newly_created_pairs)
        logger.info(f"å·²æ·»åŠ å¹¶ä¿å­˜ {len(newly_created_pairs)} ä¸ªDPOæ•°æ®å¯¹ã€‚")

    next_index = current_index + 1
    save_session(annotation_queue, next_index, dpo_data)
    return display_annotation_item(annotation_queue, next_index, dpo_data)


def start_new_round():
    gr.Info("å‡†å¤‡å¼€å§‹æ–°ä¸€è½®æ ‡æ³¨ã€‚")
    clear_session()
    return (
        gr.update(visible=True), gr.update(visible=False), gr.update(visible=False),
        [], [], 0, "", []
    )


# --- Gradio ç•Œé¢å®šä¹‰ ---
with gr.Blocks(theme=gr.themes.Soft(), title="DPO æ‰¹é‡æ ‡æ³¨å™¨ v7") as demo:
    dpo_dataset_state = gr.State([])
    annotation_queue_state = gr.State([])
    current_index_state = gr.State(0)

    gr.Markdown("# ğŸ“ DPO æ‰¹é‡æ ‡æ³¨å™¨ v7")
    gr.Markdown("é€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ªæœ€ä½³å›å¤ï¼Œæ•°æ®å°†**è‡ªåŠ¨ä¿å­˜**ã€‚æ”¯æŒæ–­ç‚¹ç»­æ ‡ã€‚")

    with gr.Group(visible=True) as setup_box:
        gr.Markdown("### ç¬¬ 1 æ­¥: é…ç½®")
        with gr.Row():
            start_btn = gr.Button("ğŸš€ å¼€å§‹æ–°æ ‡æ³¨æµç¨‹", variant="primary")
            resume_btn = gr.Button("ğŸ”„ æ¢å¤ä¸Šæ¬¡ä¼šè¯")
        num_responses_input = gr.Slider(minimum=2, maximum=MAX_RESPONSES, value=3, step=1, label="æ¯ä¸ªæç¤ºç”Ÿæˆå‡ ä¸ªå›å¤")
        user_prompt_input = gr.Textbox(lines=8, label="ç”¨æˆ·æç¤º", value=INITIAL_USER_PROMPT)

    with gr.Group(visible=False) as annotation_box:
        progress_text_output = gr.Markdown("### æ­£åœ¨å®¡æ ¸ç¬¬ 1 / X ç»„")
        gr.Markdown("ğŸ’¡ **æç¤º:** å‹¾é€‰æ‰€æœ‰æ»¡æ„å›å¤åï¼Œç‚¹å‡»ä¸‹æ–¹â€œç¡®è®¤â€æŒ‰é’®ã€‚")
        system_prompt_output = gr.Textbox(label="ç³»ç»Ÿæç¤º", lines=4, interactive=False)
        user_prompt_output = gr.Textbox(label="ç”¨æˆ·æç¤º", lines=4, interactive=False)

        response_rows = [];
        response_outputs = [];
        choice_checkboxes = []
        for i in range(MAX_RESPONSES):
            with gr.Row(visible=False) as row:
                response_rows.append(row)
                with gr.Column(scale=9):
                    response_outputs.append(gr.Textbox(lines=3, label=f"å›å¤ {i + 1}", interactive=True))
                with gr.Column(scale=1, min_width=120):
                    choice_checkboxes.append(gr.Checkbox(label="é€‰ä¸ºæœ€ä½³", elem_id=f"choice_cb_{i}"))

        with gr.Row():
            confirm_btn = gr.Button("âœ… ç¡®è®¤é€‰æ‹©å¹¶è¿›å…¥ä¸‹ä¸€ç»„", variant="primary")
            skip_btn = gr.Button("â© è·³è¿‡æ­¤ç»„")
            regenerate_btn = gr.Button("ğŸ”„ é‡æ–°ç”Ÿæˆæ­¤ç»„", variant="secondary")

    with gr.Group(visible=False) as completion_box:
        gr.Markdown("## ğŸ‰ å…¨éƒ¨å®¡æ ¸å®Œæˆï¼")
        gr.Markdown(f"æ‰€æœ‰æ•°æ®å‡å·²è‡ªåŠ¨å¢é‡ä¿å­˜åˆ° **{OUTPUT_FILE}**ã€‚")
        start_new_round_btn = gr.Button("ğŸ”„ å¼€å§‹æ–°ä¸€è½®æ ‡æ³¨", variant="primary")

    dataset_preview = gr.JSON(label="å½“å‰ä¼šè¯æ•°æ®é›†é¢„è§ˆ")

    # --- äº‹ä»¶å¤„ç†å™¨ (v7 æ ¸å¿ƒä¿®å¤) ---

    # ä¸»UIæ›´æ–°çš„è¾“å‡ºåˆ—è¡¨ (ä¸åŒ…å«checkboxes)
    main_process_outputs = [
                               annotation_queue_state, current_index_state, dpo_dataset_state,
                               setup_box, annotation_box, completion_box,
                               system_prompt_output, user_prompt_output, progress_text_output, dataset_preview
                           ] + response_outputs + response_rows

    # å¯åŠ¨å’Œæ¢å¤æŒ‰é’®
    start_btn.click(
        fn=start_batch_generation,
        inputs=[user_prompt_input, num_responses_input],
        outputs=main_process_outputs
    ).then(
        fn=reset_checkboxes_only, inputs=choice_checkboxes, outputs=choice_checkboxes
    )

    resume_btn.click(
        fn=resume_flow,
        inputs=[],
        outputs=main_process_outputs
    ).then(
        fn=reset_checkboxes_only, inputs=choice_checkboxes, outputs=choice_checkboxes
    )

    # é‡æ–°ç”ŸæˆæŒ‰é’®
    regenerate_main_outputs = [annotation_queue_state] + response_outputs
    regenerate_btn.click(
        fn=regenerate_current_set,
        inputs=[annotation_queue_state, current_index_state, dpo_dataset_state],
        outputs=regenerate_main_outputs
    ).then(
        fn=reset_checkboxes_only, inputs=choice_checkboxes, outputs=choice_checkboxes
    )

    # ç¡®è®¤å’Œè·³è¿‡æŒ‰é’®
    inputs_for_processing = [dpo_dataset_state, annotation_queue_state,
                             current_index_state] + response_outputs + choice_checkboxes

    confirm_btn.click(
        fn=process_and_advance,
        inputs=inputs_for_processing,
        outputs=main_process_outputs
    ).then(
        fn=lambda d: d, inputs=[dpo_dataset_state], outputs=[dataset_preview]
    ).then(
        fn=reset_checkboxes_only, inputs=choice_checkboxes, outputs=choice_checkboxes
    )

    skip_btn.click(
        fn=process_and_advance,
        inputs=[dpo_dataset_state, annotation_queue_state, current_index_state] + response_outputs + [
            gr.Checkbox(value=False, visible=False)] * MAX_RESPONSES,
        outputs=main_process_outputs
    ).then(
        fn=lambda d: d, inputs=[dpo_dataset_state], outputs=[dataset_preview]
    ).then(
        fn=reset_checkboxes_only, inputs=choice_checkboxes, outputs=choice_checkboxes
    )

    # å¼€å§‹æ–°ä¸€è½®æŒ‰é’®
    start_new_round_outputs = [
        setup_box, annotation_box, completion_box,
        dpo_dataset_state, annotation_queue_state, current_index_state,
        progress_text_output, dataset_preview
    ]
    start_new_round_btn.click(
        fn=start_new_round,
        inputs=[],
        outputs=start_new_round_outputs
    )

if __name__ == "__main__":
    demo.launch(server_name='0.0.0.0',share=True)